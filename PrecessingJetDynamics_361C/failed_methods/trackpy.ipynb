{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.5\n"
     ]
    }
   ],
   "source": [
    "#purpose is to generate images in the steps below, first collecting some files\n",
    "'''\n",
    "Paths and file needs:\n",
    "*imglams and spitzer_conversions are excel files, right now I have it so you need to put it as same directory as your code (but could later maybe just give it a path to go to - would be smarter)\n",
    "*paths to images and data in general\n",
    "'''\n",
    "#now the steps\n",
    "'''\n",
    "1) read in all the data by noting all the paths to given spitzer and hubble images\n",
    "2) loop through all the data, read it in, convert units\n",
    "3) cutout all the data as appropriate\n",
    "3) create a loop or otherwise hardcode going through all the combinations of convolutions of images by hand...\n",
    "4) regrid all the images\n",
    "5) de-extinct all the images\n",
    "6) create apertures as appropriate for all the knots\n",
    "7) perform relevant analyses: e.g. taking ratio and then finding EDFs, summing up the intensities of each knot for noting and saving\n",
    "'''\n",
    "\n",
    "#just to check python version - should be 3.7.4\n",
    "from platform import python_version\n",
    "print(python_version())\n",
    "\n",
    "#importing libraries\n",
    "from astropy.io import fits\n",
    "from astropy.convolution import convolve, Gaussian2DKernel, Box2DKernel\n",
    "from astropy.nddata import Cutout2D\n",
    "from astropy.wcs import WCS\n",
    "\n",
    "import glob\n",
    "import itertools\n",
    "import matplotlib \n",
    "%matplotlib inline\n",
    "# matplotlib.use('Agg') #invokved b/c just plain matplotlib was insufficient\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "import pims\n",
    "import trackpy as tp\n",
    "import os\n",
    "\n",
    "#this part is unnecessary...in jupyter...point was to test blocks of code\n",
    "#switches for the three different parts of this code\n",
    "# switch1 = 'on' #convolving images [needed to put it on for switch 3 at min...need to figure out other solution, eh]\n",
    "# switch1b = 'on' #regridding...\n",
    "# switch2 = 'on' #solving equations\n",
    "# switch3 = 'on' #plotting / graphics of solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #finding the path to every fits images in a directory\n",
    "def im_name_finder(path, file_type):\n",
    "    #Using glob (it's a unix command similar to ls)\n",
    "    #WARNING: using recursive=True...depending how many images you use this could be very slow, it's recommended not to have too many subfolders\n",
    "    #if needed, some example code is commented towards the latter half of this code that could help make an alternative\n",
    "    all_names = glob.glob(path, recursive=True)\n",
    "\n",
    "    #IMPORTANT: Using \"fit\" here because it is inclusive of both fits and FIT...some files end in \"FIT\" and need to be included\n",
    "    #using s.lower() include uppercase names\n",
    "    im_names = [s for s in all_names if 'fit' in s.lower()]\n",
    "\n",
    "    return im_names\n",
    "\n",
    "\n",
    "'''now convolve my image with a PSF of the image we're projecting ONTO\n",
    "an approx PSF can be found by assuming a 2D Gaussian func with a width (a FWHM) of the diffrac limit\n",
    "that is the st dev of the Gaussian is about the st dev is about = lambda/D\n",
    "a list of PSFs are found on https://docs.astropy.org/en/stable/convolution/kernels.html\n",
    "\n",
    "Notes:\n",
    "FIRST: always must convert hdu1_pixtorad to radians! It's inconsistent otherwise, and lambda/D is generally in radians\n",
    "\n",
    "what we're using for the gaussian width is the FWHM, not the radius of the first ring of the diffraction pattern,\n",
    "so it's 1.2 not 1.22 times lambda/D\n",
    "\n",
    "D is 85 cm for spitzer\n",
    "D is 2.4 m for hubble\n",
    "'''\n",
    "\n",
    "def im_conv(D, hdu_pix_torad, hdu_dat, lam, kern):\n",
    "    #gaussian kernel\n",
    "    if kern == 'gauss':\n",
    "        #update: usually cannot find wavelength but these headers are well-labeled    \n",
    "        #finding angular resolution...the FWHM of our Gaussian PSF\n",
    "        res = 1.2 * lam / D         #resolution in radians\n",
    "        res = res / hdu_pix_torad        #so converting to pixels\n",
    "\n",
    "        #finding PSF and then calculating the convolution of our image and the PSF of the image we're projecting onto\n",
    "        kernel = Gaussian2DKernel(res)\n",
    "\n",
    "    #box kernel\n",
    "    if kern == 'box':\n",
    "        kernel = Box2DKernel(16.)\n",
    "\n",
    "    hdu_conv = convolve(hdu_dat, kernel)\n",
    "    return hdu_conv\n",
    "\n",
    "# In[27]:\n",
    "\n",
    "#setting up a new fits file to be saved and viewed in DS9\n",
    "#primarily to save the image we reprojected, but can also be used to save the convolved images\n",
    "def fits_saver(array, wcs_header, name, save_path):\n",
    "    '''\n",
    "    array is a 2d array of data - could be from reprojecting one image onto another or from convolution\n",
    "    wcs_header is a header containing the wcs coords of the image that we projected onto or of the orig image (if from the convolution)\n",
    "    name is the path to some image you're using. It will get string split at the / character, and the func only takes the last element of that splitting\n",
    "    save_path is the folder you want to save to...recommended to also add something to the start of the images names to make it clear what you did to them (e.g. 'Regridded/regrid_')\n",
    "    '''\n",
    "\n",
    "    #creating a new file and adding the reprojected array of data as well as the WCS that we projected onto\n",
    "    hdu_new = fits.PrimaryHDU(array, header=wcs_header)\n",
    "    hdul = fits.HDUList([hdu_new])\n",
    "    \n",
    "    #saving the file\n",
    "    if name.find('FIT') == -1: #needed if file end incorrect\n",
    "        new_filename = name.split('/')[-1]  #grabs the file name we were using from before\n",
    "        hdul.writeto(save_path+new_filename, overwrite=True)\n",
    "    else:\n",
    "        name_fixfit = name[:-3] + 'fits'\n",
    "        new_filename = name_fixfit.split('/')[-1]  #grabs the file name we were using from before\n",
    "        hdul.writeto(save_path+new_filename, overwrite=True)\n",
    "        \n",
    "    return (save_path+new_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code uses TrackPy...\n",
    "\n",
    "http://soft-matter.github.io/trackpy/v0.5.0/tutorial/custom-feature-detection.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../scaling_for_motions/160_epoch1_scaled.fits', '../scaling_for_motions/160_epoch2_synth_scaled.fits']\n"
     ]
    }
   ],
   "source": [
    "# path = '../../Montage_results/n2071_headercut/*drz.fits' # #using ** will grab all files even in subdirectories WARNING takes longer\n",
    "# im_names_n2071 = sorted(im_name_finder(path, 'fit')) #im_finder is basically glob.glob\n",
    "# im_names_n2071 = [i.replace('\\\\', '/') for i in im_names_n2071]\n",
    "im_names_n2071 = ['../scaling_for_motions/160_epoch1_scaled.fits', '../scaling_for_motions/160_epoch2_synth_scaled.fits']\n",
    "\n",
    "print(im_names_n2071)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdu_list = [fits.open(i) for i in im_names_n2071]\n",
    "\n",
    "#initializing some lists to be used\n",
    "hdu_pix_list = []\n",
    "hdu_pixtorad_list = []\n",
    "# hdu_fnu_list = []\n",
    "hdu_lam_list = []\n",
    "# hdu_flam_list = []\n",
    "# hdu_bw_list = []\n",
    "hdu_data_list = []\n",
    "hdu_header_list = []\n",
    "\n",
    "count = 0\n",
    "for hdu_data in hdu_list:   \n",
    "    #reading in conversions\n",
    "#     hdu_pix_list.append(hdu_data[0].header['D001SCAL'])  #D001SCAL is the keyword for Hubble images, in sr\n",
    "#     hdu_pixtorad_list.append(hdu_pix_list[count] / 206265.)\n",
    "    # hdu_fnu_list.append(hdu_units[0].header['PHOTFNU'])\n",
    "#     hdu_lam_list.append(hdu_data[0].header['PHOTFLAM'])\n",
    "#     hdu_flam_list.append(hdu_list[0].header['PHOTFLAM'])\n",
    "#     hdu_bw_list.append(hdu_list[0].header['PHOTBW'])\n",
    "\n",
    "    #reading in data for general use  and header for wcs\n",
    "    #converting by times by flam * bw from e-/sec...should get units of erg/cm^2/sec as above\n",
    "    hdu_data_list.append(hdu_data[0].data) # * hdu_list[0].header['PHOTFLAM'] * hdu_list[0].header['PHOTBW'])\n",
    "    hdu_header_list.append(hdu_data[0].header)\n",
    "    \n",
    "    count+=1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypingError",
     "evalue": "Failed in nopython mode pipeline (step: nopython frontend)\n\u001b[1m\u001b[1mnon-precise type pyobject\u001b[0m\n\u001b[0m\u001b[1mDuring: typing of argument at C:\\Users\\arubi\\anaconda3\\lib\\site-packages\\trackpy\\refine\\center_of_mass.py (362)\u001b[0m\n\u001b[1m\nFile \"..\\..\\..\\..\\..\\..\\..\\..\\anaconda3\\lib\\site-packages\\trackpy\\refine\\center_of_mass.py\", line 362:\u001b[0m\n\u001b[1mdef _numba_refine_2D_c(raw_image, image, radiusY, radiusX, coords, N,\n    <source elided>\n    # Column indices into the 'results' array\n\u001b[1m    MASS_COL = 2\n\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n\nThis error may have been caused by the following argument(s):\n- argument 0: Unsupported array dtype: >f8\n\nThis error may have been caused by the following argument(s):\n- argument 0: Unsupported array dtype: >f8\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypingError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-7b80767b133e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mticker\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLogFormatter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLogLocator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFixedLocator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFixedFormatter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlocate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhdu_data_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[0mtp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mannotate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhdu_data_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\trackpy\\feature.py\u001b[0m in \u001b[0;36mlocate\u001b[1;34m(raw_image, diameter, minmass, maxsize, separation, noise_size, smoothing_size, threshold, invert, percentile, topn, preprocess, max_iterations, filter_before, filter_after, characterize, engine)\u001b[0m\n\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m     \u001b[1;31m# Refine their locations and characterize mass, size, etc.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 397\u001b[1;33m     refined_coords = refine_com(raw_image, image, radius, coords,\n\u001b[0m\u001b[0;32m    398\u001b[0m                                 \u001b[0mmax_iterations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_iterations\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m                                 engine=engine, characterize=characterize)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\trackpy\\refine\\center_of_mass.py\u001b[0m in \u001b[0;36mrefine_com\u001b[1;34m(raw_image, image, radius, coords, max_iterations, engine, shift_thresh, characterize, pos_columns)\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m     refined = refine_com_arr(raw_image, image, radius, coords,\n\u001b[0m\u001b[0;32m     92\u001b[0m                              \u001b[0mmax_iterations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_iterations\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m                              \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshift_thresh\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshift_thresh\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\trackpy\\refine\\center_of_mass.py\u001b[0m in \u001b[0;36mrefine_com_arr\u001b[1;34m(raw_image, image, radius, coords, max_iterations, engine, shift_thresh, characterize, walkthrough)\u001b[0m\n\u001b[0;32m    179\u001b[0m             \u001b[0mcmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcosmask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mradius\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m             \u001b[0msmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msinmask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mradius\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 181\u001b[1;33m             _numba_refine_2D_c(np.asarray(raw_image), np.asarray(image),\n\u001b[0m\u001b[0;32m    182\u001b[0m                                \u001b[0mradius\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mradius\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m                                \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_iterations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshift_thresh\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numba\\core\\dispatcher.py\u001b[0m in \u001b[0;36m_compile_for_args\u001b[1;34m(self, *args, **kws)\u001b[0m\n\u001b[0;32m    413\u001b[0m                 \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpatch_message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    414\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 415\u001b[1;33m             \u001b[0merror_rewrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'typing'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    416\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUnsupportedError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    417\u001b[0m             \u001b[1;31m# Something unsupported is present in the user code, add help info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numba\\core\\dispatcher.py\u001b[0m in \u001b[0;36merror_rewrite\u001b[1;34m(e, issue_type)\u001b[0m\n\u001b[0;32m    356\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 358\u001b[1;33m                 \u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    359\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    360\u001b[0m         \u001b[0margtypes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numba\\core\\utils.py\u001b[0m in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb)\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypingError\u001b[0m: Failed in nopython mode pipeline (step: nopython frontend)\n\u001b[1m\u001b[1mnon-precise type pyobject\u001b[0m\n\u001b[0m\u001b[1mDuring: typing of argument at C:\\Users\\arubi\\anaconda3\\lib\\site-packages\\trackpy\\refine\\center_of_mass.py (362)\u001b[0m\n\u001b[1m\nFile \"..\\..\\..\\..\\..\\..\\..\\..\\anaconda3\\lib\\site-packages\\trackpy\\refine\\center_of_mass.py\", line 362:\u001b[0m\n\u001b[1mdef _numba_refine_2D_c(raw_image, image, radiusY, radiusX, coords, N,\n    <source elided>\n    # Column indices into the 'results' array\n\u001b[1m    MASS_COL = 2\n\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n\nThis error may have been caused by the following argument(s):\n- argument 0: Unsupported array dtype: >f8\n\nThis error may have been caused by the following argument(s):\n- argument 0: Unsupported array dtype: >f8\n"
     ]
    }
   ],
   "source": [
    "from scipy import ndimage\n",
    "from skimage import morphology, util, filters\n",
    "\n",
    "@pims.pipeline\n",
    "def preprocess_foam(img):\n",
    "    \"\"\"\n",
    "    Apply image processing functions to return a binary image\n",
    "    \"\"\"\n",
    "    # Crop the pictures as for raw images.\n",
    "    # Apply thresholds\n",
    "    img_crop = img\n",
    "    print(img_crop, img_crop.shape)\n",
    "    adaptive_thresh = filters.threshold_local(img_crop,1)\n",
    "    idx = img_crop > adaptive_thresh\n",
    "    idx2 = img_crop < adaptive_thresh\n",
    "    img_crop[idx] = 0\n",
    "    img_crop[idx2] = 255\n",
    "    img_crop = ndimage.binary_dilation(img_crop)\n",
    "    img_crop = ndimage.binary_dilation(img_crop)\n",
    "    return util.img_as_int(img_crop)\n",
    "\n",
    "#plotting resulting image\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy import units as u\n",
    "from astropy.utils.data import get_pkg_data_filename\n",
    "from astropy.visualization import ZScaleInterval, ImageNormalize, PercentileInterval\n",
    "from astropy.visualization.stretch import SinhStretch, AsinhStretch, LogStretch\n",
    "from astropy.visualization.wcsaxes import WCSAxesSubplot\n",
    "from astropy.wcs import WCS\n",
    "from astropy.wcs.utils import skycoord_to_pixel\n",
    "import matplotlib.ticker\n",
    "from matplotlib.ticker import LogFormatter, LogLocator, FixedLocator, FixedFormatter\n",
    "\n",
    "f = tp.locate(hdu_data_list[0], 15)\n",
    "tp.annotate(f, hdu_data_list[0])\n",
    "\n",
    "sys.exit()\n",
    "\n",
    "fig = plt.figure(figsize=(20,20))\n",
    "wcs = WCS(hdu_header_list[0])\n",
    "ax = plt.subplot(projection=wcs)\n",
    "\n",
    "#plotting\n",
    "interval = PercentileInterval(99)\n",
    "data_interval = interval.get_limits(hdu_data_list[0])\n",
    "ds9_min = -1.64092e-17\n",
    "ds9_max = 3.19425e-16\n",
    "norm = ImageNormalize(stretch=AsinhStretch(), vmin=data_interval[0], vmax=data_interval[1])\n",
    "# norm = ImageNormalize(stretch=SinhStretch(), vmin=ds9_min, vmax=ds9_max)\n",
    "# norm = ImageNormalize(stretch=AsinhStretch(), vmin=-8e-18, vmax=8e-18)\n",
    "# norm = ImageNormalize(stretch=LogStretch(), vmin=0.1e-18, vmax=100e-18)\n",
    "\n",
    "id_example = 0\n",
    "# frames = preprocess_foam(hdu_data_list[0]) #   pims.open(os.path.join(datapath, prefix + '*.tif')))\n",
    "im = ax.imshow(hdu_data_list[0], norm=norm, origin='lower', cmap='Greens_r')\n",
    "# hops_sources = [ax.scatter(c_pair[0], c_pair[1], color='gold', marker='+', s=100) for c_pair in coord_pix_list]\n",
    "\n",
    "#general formatting\n",
    "ax.coords.grid(True, color='black', ls='solid', linewidth=0.75) #adding gridlines\n",
    "ax.coords[0].set_axislabel('Right Ascension (J2000)', fontsize=30)\n",
    "ax.coords[1].set_axislabel('Declination (J2000)', fontsize=30)   \n",
    "ax.tick_params(axis='x', labelbottom=True, labeltop=False, labelright=False)\n",
    "ax.tick_params(axis='x', labelsize=20)\n",
    "ax.tick_params(axis='y', labelsize=20)\n",
    "ax.invert_yaxis() #done because it's nicer with declination increasing\n",
    "ax.invert_xaxis() #done because it's nicer with declination increasing\n",
    "\n",
    "#colorbar, see 3rd answer from https://stackoverflow.com/questions/18195758/set-matplotlib-colorbar-size-to-match-graph\n",
    "cax = fig.add_axes([ax.get_position().x1+0.01,ax.get_position().y0,0.02,ax.get_position().height])\n",
    "cbar = plt.colorbar(im, cax=cax) \n",
    "\n",
    "#color bar label and tick labels\n",
    "# sub_labels = [2]\n",
    "# cbar.locator = LogLocator(base=10, subs=sub_labels)\n",
    "cbar.ax.tick_params(labelsize=20)\n",
    "cbar.update_ticks()\n",
    "cbar.ax.yaxis.get_offset_text().set_fontsize(0)\n",
    "cbar.set_label(label=r'$\\rm Intensity~(x~{10}^{-18}~erg/s/{cm}^{2}/pix)$', size=20)\n",
    "# cbar_tickfont = [cbar.ax.set_yticklabels(labels=cbar.ax.get_yticklabels())[i].set_fontweight('normal') for i in range(len(cbar.ax.get_yticklabels()))]\n",
    "# plt.savefig('f164n_epoch_2.png', dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "# fits_saver(frames, hdu_header_list[0], '160_epoch1.fits', '') #max determined from fits file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#our plotting function\n",
    "def implot(data, w, wcscond, vmax_p):\n",
    "    fig = plt.figure()\n",
    "    \n",
    "    if  wcscond == True:\n",
    "        fig.add_subplot(111, projection=w)\n",
    "    else:\n",
    "        fig.add_subplot(111)\n",
    "    \n",
    "    #for christmas turn on GnRd\n",
    "    #plt.cm.get_cmap('Blues', 6) is another option\n",
    "    #can also use RdBu...\n",
    "    #otherwise just use plt.cm.viridis b/c it works\n",
    "    plt.imshow(data, origin='lower', cmap=plt.cm.viridis, vmin =0, vmax=vmax_p)\n",
    "    plt.xlabel('RA')\n",
    "    plt.ylabel('Dec')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
